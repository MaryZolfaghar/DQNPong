{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearner(nn.Module):\n",
    "    def __init__(self, env, args, replay_buffer):\n",
    "        super(QLearner, self).__init__()\n",
    "\n",
    "        self.batch_size = args.batch_size\n",
    "        self.gamma = args.gamma\n",
    "        self.num_frames = args.num_frames\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.env = env\n",
    "        self.input_shape = self.env.observation_space.shape\n",
    "        self.num_actions = self.env.action_space.n\n",
    "        self.N = args.N\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(self.input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size(), 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.num_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def feature_size(self):\n",
    "            return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "\n",
    "    def act(self, state, epsilon):\n",
    "        action = []\n",
    "\n",
    "        if random.random() > epsilon:\n",
    "            state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), \\\n",
    "                               requires_grad=True)\n",
    "            ######## YOUR CODE HERE! ########\n",
    "            # TODO: Given state, you should write code to get the Q value and chosen action\n",
    "            # Complete the R.H.S. of the following 2 lines and uncomment them\n",
    "            q_value = self.forward(state)\n",
    "            action = torch.argmax(q_value)\n",
    "            ######## YOUR CODE HERE! ########\n",
    "        else:\n",
    "            action = random.randrange(self.env.action_space.n)\n",
    "        return action\n",
    "        \n",
    "def compute_td_loss(model, batch_size, gamma, replay_buffer):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "    \n",
    "    state = Variable(torch.FloatTensor(np.float32(state)), requires_grad=True)\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), requires_grad=True)\n",
    "    action = Variable(torch.LongTensor(action))\n",
    "    reward = Variable(torch.FloatTensor(reward))\n",
    "    done = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    ######## YOUR CODE HERE! ########\n",
    "    # TODO: Implement the Temporal Difference Loss\n",
    "    q_value = model.forward(state)\n",
    "    next_q_value = model.forward(next_state)\n",
    "    \n",
    "    target = reward + gamma*torch.max(next_q_value)\n",
    "    current = [q_value[ii,act] for ii, act in enumerate(action)]\n",
    "    current = Variable(torch.FloatTensor(np.float32(current)), requires_grad=True)\n",
    "    \n",
    "    loss = torch.sqrt(torch.mean((current - target)**2))\n",
    "    ######## YOUR CODE HERE! ########\n",
    "    return loss\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        #Returns a new deque object initialized left-to-right\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        ######## YOUR CODE HERE! ########\n",
    "        # TODO: Randomly sampling data with specific batch size from the buffer\n",
    "        # Hint: you may use the python library \"random\".\n",
    "\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "#         state  = []\n",
    "#         action = []\n",
    "#         reward = []\n",
    "#         next_state = []\n",
    "#         done = []\n",
    "#         for sample in batch:\n",
    "#             state.append(sample[0])\n",
    "#             action.append(sample[1])\n",
    "#             reward.append(sample[2])\n",
    "#             next_state.append(sample[3])\n",
    "#             done.append(sample[4])\n",
    "\n",
    "        # If you are not familiar with the \"deque\" python library, please google it.\n",
    "        ######## YOUR CODE HERE! ########\n",
    "        return batch\n",
    "#         return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.seed=1\n",
    "        self.batch_size = 32\n",
    "        self.num_frames = 1000000\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon_start = 1.0\n",
    "        self.epsilon_final = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.N = 1\n",
    "        self.optimizer = 'Adam'\n",
    "        self.lr = 1e-4\n",
    "        self.capacity = 100000\n",
    "        self.save_result_path = '../results/DQN/results.npy'\n",
    "        self.save_model_path = '../results/DQN/weights_only.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0930)\n",
      "tensor(1.0930)\n"
     ]
    }
   ],
   "source": [
    "aa=torch.tensor([[ 0.0616, -1.5050, -1.2542,  1.0467, -1.6583, -0.1956],\n",
    "        [ 0.1444, -1.4500, -1.2947,  1.0930, -1.7403, -0.2409],\n",
    "        [ 0.0342, -1.5723, -1.2624,  1.1574, -1.6852, -0.0689],\n",
    "        [ 0.0517, -1.5105, -1.2464,  1.1025, -1.6326, -0.1251],\n",
    "        [ 0.0201, -1.5424, -1.2026,  1.1654, -1.7247, -0.1792],\n",
    "        [ 0.0877, -1.4870, -1.2158,  1.0617, -1.6393, -0.1004],\n",
    "        [ 0.0881, -1.4855, -1.2736,  1.1042, -1.5769, -0.1997],\n",
    "        [ 0.1076, -1.4818, -1.2331,  1.0620, -1.6394, -0.1209],\n",
    "        [ 0.1458, -1.5549, -1.1906,  1.1144, -1.6783, -0.0942],\n",
    "        [ 0.0267, -1.5309, -1.3258,  1.0811, -1.6813, -0.1498],\n",
    "        [ 0.0187, -1.5255, -1.3182,  1.0463, -1.6692, -0.0902],\n",
    "        [ 0.0642, -1.6106, -1.2788,  1.0466, -1.6537, -0.0168],\n",
    "        [-0.0481, -1.5233, -1.2429,  1.0540, -1.6389, -0.1518],\n",
    "        [-0.0229, -1.4506, -1.2753,  0.9652, -1.6470, -0.2397],\n",
    "        [ 0.0108, -1.5544, -1.1406,  1.1781, -1.7532, -0.1468],\n",
    "        [ 0.1174, -1.5528, -1.2626,  1.0589, -1.6256, -0.1757],\n",
    "        [ 0.0499, -1.5252, -1.2493,  1.1104, -1.6591, -0.0693],\n",
    "        [ 0.0906, -1.5743, -1.2251,  1.0825, -1.6204, -0.0840],\n",
    "        [ 0.0260, -1.5498, -1.2999,  1.1594, -1.6374, -0.1158],\n",
    "        [ 0.0567, -1.4924, -1.2527,  1.0692, -1.6544, -0.1253],\n",
    "        [ 0.0356, -1.5186, -1.3110,  1.1103, -1.7097, -0.0847],\n",
    "        [ 0.0463, -1.5214, -1.2331,  1.0992, -1.6376, -0.1251],\n",
    "        [ 0.0372, -1.4996, -1.2329,  1.0936, -1.6099, -0.0969],\n",
    "        [ 0.0567, -1.5007, -1.2477,  1.0955, -1.6199, -0.1252],\n",
    "        [ 0.0213, -1.5079, -1.2459,  1.1022, -1.6472, -0.1064],\n",
    "        [ 0.0600, -1.4948, -1.2267,  1.0692, -1.6599, -0.1107],\n",
    "        [ 0.0256, -1.5184, -1.2491,  1.1132, -1.6322, -0.1291],\n",
    "        [ 0.1561, -1.5188, -1.2421,  1.1181, -1.6393, -0.1787],\n",
    "        [ 0.0355, -1.5439, -1.2369,  1.1085, -1.6272, -0.1101],\n",
    "        [ 0.0417, -1.4993, -1.3280,  1.0897, -1.6234, -0.1404],\n",
    "        [ 0.0097, -1.5227, -1.2437,  1.0888, -1.6143, -0.1501],\n",
    "        [ 0.0409, -1.6244, -1.4683,  1.1526, -1.8225, -0.1008]]) \n",
    "print(max(aa[1]))\n",
    "\n",
    "print(max(aa[1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run DQN Pong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/Maryam/anaconda3/lib/python3.6/site-packages/cv2/cv2.cpython-36m-darwin.so, 2): Symbol not found: _inflateValidate\n  Referenced from: /Users/Maryam/anaconda3/lib/python3.6/site-packages/cv2/.dylibs/libpng16.16.dylib (which was built for Mac OS X 10.13)\n  Expected in: /usr/lib/libz.1.dylib\n in /Users/Maryam/anaconda3/lib/python3.6/site-packages/cv2/.dylibs/libpng16.16.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-21e47247b44c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mocl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetUseOpenCL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/Maryam/anaconda3/lib/python3.6/site-packages/cv2/cv2.cpython-36m-darwin.so, 2): Symbol not found: _inflateValidate\n  Referenced from: /Users/Maryam/anaconda3/lib/python3.6/site-packages/cv2/.dylibs/libpng16.16.dylib (which was built for Mac OS X 10.13)\n  Expected in: /usr/lib/libz.1.dylib\n in /Users/Maryam/anaconda3/lib/python3.6/site-packages/cv2/.dylibs/libpng16.16.dylib"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import gym\n",
    "from gym import spaces\n",
    "import cv2\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "class NoopResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env, noop_max=30):\n",
    "        \"\"\"Sample initial states by taking random number of no-ops on reset.\n",
    "        No-op is assumed to be action 0.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.noop_max = noop_max\n",
    "        self.override_num_noops = None\n",
    "        self.noop_action = 0\n",
    "        assert env.unwrapped.get_action_meanings()[0] == 'NOOP'\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"\n",
    "        self.env.reset(**kwargs)\n",
    "        if self.override_num_noops is not None:\n",
    "            noops = self.override_num_noops\n",
    "        else:\n",
    "            noops = self.unwrapped.np_random.randint(1, self.noop_max + 1) #pylint: disable=E1101\n",
    "        assert noops > 0\n",
    "        obs = None\n",
    "        for _ in range(noops):\n",
    "            obs, _, done, _ = self.env.step(self.noop_action)\n",
    "            if done:\n",
    "                obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "\n",
    "class FireResetEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Take action on reset for environments that are fixed until firing.\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
    "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        self.env.reset(**kwargs)\n",
    "        obs, _, done, _ = self.env.step(1)\n",
    "        if done:\n",
    "            self.env.reset(**kwargs)\n",
    "        obs, _, done, _ = self.env.step(2)\n",
    "        if done:\n",
    "            self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, ac):\n",
    "        return self.env.step(ac)\n",
    "\n",
    "class EpisodicLifeEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n",
    "        Done by DeepMind for the DQN and co. since it helps value estimation.\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.lives = 0\n",
    "        self.was_real_done  = True\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.was_real_done = done\n",
    "        # check current lives, make loss of life terminal,\n",
    "        # then update lives to handle bonus lives\n",
    "        lives = self.env.unwrapped.ale.lives()\n",
    "        if lives < self.lives and lives > 0:\n",
    "            # for Qbert sometimes we stay in lives == 0 condtion for a few frames\n",
    "            # so its important to keep lives > 0, so that we only reset once\n",
    "            # the environment advertises done.\n",
    "            done = True\n",
    "        self.lives = lives\n",
    "        return obs, reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        \"\"\"Reset only when lives are exhausted.\n",
    "        This way all states are still reachable even though lives are episodic,\n",
    "        and the learner need not know about any of this behind-the-scenes.\n",
    "        \"\"\"\n",
    "        if self.was_real_done:\n",
    "            obs = self.env.reset(**kwargs)\n",
    "        else:\n",
    "            # no-op step to advance from terminal/lost life state\n",
    "            obs, _, _, _ = self.env.step(0)\n",
    "        self.lives = self.env.unwrapped.ale.lives()\n",
    "        return obs\n",
    "\n",
    "class MaxAndSkipEnv(gym.Wrapper):\n",
    "    def __init__(self, env, skip=4):\n",
    "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        # most recent raw observations (for max pooling across time steps)\n",
    "        self._obs_buffer = np.zeros((2,)+env.observation_space.shape, dtype=np.uint8)\n",
    "        self._skip       = skip\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Repeat action, sum reward, and max over last observations.\"\"\"\n",
    "        total_reward = 0.0\n",
    "        done = None\n",
    "        for i in range(self._skip):\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "            if i == self._skip - 2: self._obs_buffer[0] = obs\n",
    "            if i == self._skip - 1: self._obs_buffer[1] = obs\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        # Note that the observation on the done=True frame\n",
    "        # doesn't matter\n",
    "        max_frame = self._obs_buffer.max(axis=0)\n",
    "\n",
    "        return max_frame, total_reward, done, info\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        return self.env.reset(**kwargs)\n",
    "\n",
    "class ClipRewardEnv(gym.RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.RewardWrapper.__init__(self, env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        \"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"\n",
    "        return np.sign(reward)\n",
    "\n",
    "class WarpFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Warp frames to 84x84 as done in the Nature paper and later work.\"\"\"\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "        self.width = 84\n",
    "        self.height = 84\n",
    "        self.observation_space = spaces.Box(low=0, high=255,\n",
    "            shape=(self.height, self.width, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        frame = cv2.resize(frame, (self.width, self.height), interpolation=cv2.INTER_AREA)\n",
    "        return frame[:, :, None]\n",
    "\n",
    "class FrameStack(gym.Wrapper):\n",
    "    def __init__(self, env, k):\n",
    "        \"\"\"Stack k last frames.\n",
    "        Returns lazy array, which is much more memory efficient.\n",
    "        See Also\n",
    "        --------\n",
    "        baselines.common.atari_wrappers.LazyFrames\n",
    "        \"\"\"\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.frames = deque([], maxlen=k)\n",
    "        shp = env.observation_space.shape\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(shp[0], shp[1], shp[2] * k), dtype=np.uint8)\n",
    "\n",
    "    def reset(self):\n",
    "        ob = self.env.reset()\n",
    "        for _ in range(self.k):\n",
    "            self.frames.append(ob)\n",
    "        return self._get_ob()\n",
    "\n",
    "    def step(self, action):\n",
    "        ob, reward, done, info = self.env.step(action)\n",
    "        self.frames.append(ob)\n",
    "        return self._get_ob(), reward, done, info\n",
    "\n",
    "    def _get_ob(self):\n",
    "        assert len(self.frames) == self.k\n",
    "        return LazyFrames(list(self.frames))\n",
    "\n",
    "class ScaledFloatFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.ObservationWrapper.__init__(self, env)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        # careful! This undoes the memory optimization, use\n",
    "        # with smaller replay buffers only.\n",
    "        return np.array(observation).astype(np.float32) / 255.0\n",
    "\n",
    "class LazyFrames(object):\n",
    "    def __init__(self, frames):\n",
    "        \"\"\"This object ensures that common frames between the observations are only stored once.\n",
    "        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n",
    "        buffers.\n",
    "        This object should only be converted to numpy array before being passed to the model.\n",
    "        You'd not believe how complex the previous solution was.\"\"\"\n",
    "        self._frames = frames\n",
    "        self._out = None\n",
    "\n",
    "    def _force(self):\n",
    "        if self._out is None:\n",
    "            self._out = np.concatenate(self._frames, axis=2)\n",
    "            self._frames = None\n",
    "        return self._out\n",
    "\n",
    "    def __array__(self, dtype=None):\n",
    "        out = self._force()\n",
    "        if dtype is not None:\n",
    "            out = out.astype(dtype)\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._force())\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self._force()[i]\n",
    "\n",
    "def make_atari(env_id):\n",
    "    env = gym.make(env_id)\n",
    "    assert 'NoFrameskip' in env.spec.id\n",
    "    env = NoopResetEnv(env, noop_max=30)\n",
    "    env = MaxAndSkipEnv(env, skip=4)\n",
    "    return env\n",
    "\n",
    "def wrap_deepmind(env, episode_life=True, clip_rewards=True, frame_stack=False, scale=False):\n",
    "    \"\"\"Configure environment for DeepMind-style Atari.\n",
    "    \"\"\"\n",
    "    if episode_life:\n",
    "        env = EpisodicLifeEnv(env)\n",
    "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
    "        env = FireResetEnv(env)\n",
    "    env = WarpFrame(env)\n",
    "    if scale:\n",
    "        env = ScaledFloatFrame(env)\n",
    "    if clip_rewards:\n",
    "        env = ClipRewardEnv(env)\n",
    "    if frame_stack:\n",
    "        env = FrameStack(env, 4)\n",
    "    return env\n",
    "\n",
    "\n",
    "\n",
    "class ImageToPyTorch(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Image shape to num_channels x weight x height\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super(ImageToPyTorch, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.swapaxes(observation, 2, 0)\n",
    "    \n",
    "\n",
    "def wrap_pytorch(env):\n",
    "    return ImageToPyTorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Wrapper.layers import *\n",
    "# from Wrapper.wrappers import make_atari, wrap_deepmind, wrap_pytorch\n",
    "import math, random\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "# from dqn import QLearner, compute_td_loss, ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"PongNoFrameskip-v4\"\n",
    "env = make_atari(env_id)\n",
    "env = wrap_deepmind(env, frame_stack=False)\n",
    "env = wrap_pytorch(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1858ac7e12f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRewardWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bf7a4444050a>\u001b[0m in \u001b[0;36mobservation\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "(state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot observation of env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_frames = 1000000\n",
    "# batch_size = 32\n",
    "# gamma = 0.99\n",
    "    \n",
    "# replay_initial = 10000\n",
    "# replay_buffer = ReplayBuffer(100000)\n",
    "# model = QLearner(env, num_frames, batch_size, gamma, replay_buffer)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "# if USE_CUDA:\n",
    "#     model = model.cuda()\n",
    "\n",
    "# epsilon_start = 1.0\n",
    "# epsilon_final = 0.01\n",
    "# epsilon_decay = 30000\n",
    "# epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n",
    "\n",
    "# losses = []\n",
    "# all_rewards = []\n",
    "# episode_reward = 0\n",
    "\n",
    "# state = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some tinkering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1745, 0.6629, 0.3745, 0.9351, 0.2654]])\n",
      "tensor([[0.0304, 0.4395, 0.1402, 0.8744, 0.0704]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1,5)\n",
    "print(a)\n",
    "print(a**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-148fb23e6607>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# model = QLearner(env, num_frames, batch_size, gamma, replay_buffer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Initialize target q function and q function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRewardWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bf7a4444050a>\u001b[0m in \u001b[0;36mobservation\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "num_frames = 10\n",
    "batch_size = 3\n",
    "gamma = 0.99\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30000\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n",
    "\n",
    "replay_buffer = ReplayBuffer(100)\n",
    "# model = QLearner(env, num_frames, batch_size, gamma, replay_buffer)\n",
    "\n",
    "state = env.reset()\n",
    "# Initialize target q function and q function\n",
    "model_Q = QLearner(env, args, replay_buffer)\n",
    "model_target_Q = QLearner(env, args, replay_buffer)\n",
    "\n",
    "for frame_idx in range(100):\n",
    "        epsilon = epsilon_by_frame(frame_idx)\n",
    "        action = model_Q.act(state, epsilon)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        replay_buffer.push(state, action, reward, next_state, done)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-dd25805d27bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# state, action, reward, next_state, done = replay_buffer.sample(batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-029edc40a755>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Hint: you may use the python library \"random\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;31m#         state  = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m#         action = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "# state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "transition = replay_buffer.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "a , b , c , d, e = zip(*transition)\n",
    "print(np.shape(transition[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got numpy.float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-00a262c18725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got numpy.float64)"
     ]
    }
   ],
   "source": [
    "state = Variable(torch.FloatTensor(np.float32(state)), requires_grad=True)\n",
    "next_state = Variable(torch.FloatTensor(np.float32(next_state)), requires_grad=True)\n",
    "action = Variable(torch.LongTensor(action))\n",
    "reward = Variable(torch.FloatTensor(reward))\n",
    "done = Variable(torch.FloatTensor(done))\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if USE_CUDA:\n",
    "#     action = action.cuda()\n",
    "#     reward = reward.cuda()\n",
    "# ######## YOUR CODE HERE! ########\n",
    "# # TODO: Implement the Temporal Difference Loss\n",
    "\n",
    "# # Compute current Q value, q_func takes only state and output value for every state-action pair\n",
    "# # We choose Q based on action taken.\n",
    "# current_q_value = model_Q.forward(state)\n",
    "# # Compute next Q value based on which action gives max Q values\n",
    "# # Detach variable from the current graph since we don't want gradients for next Q to propagated\n",
    "# with torch.no_grad():\n",
    "#     next_q_value = model_target_Q.forward(next_state).detach()\n",
    "#     target_q_val = reward + ( (gamma**args.N)* (np.max(next_q_value.detach().cpu().numpy())) * (1-done))\n",
    "\n",
    "# print(current_q_value.shape)\n",
    "# print(target_q_val.shape)\n",
    "# # Compute Bellman error\n",
    "# loss = torch.mean((target_q_val - current_q_value)**2)\n",
    "\n",
    "# # loss = torch.nn.SmoothL1Loss(target_q_val, current_q_value)\n",
    "\n",
    "# # Not sure what this is about\n",
    "# # # clip the bellman error between [-1 , 1]\n",
    "# # bellman_error = loss\n",
    "# # clipped_bellman_error = bellman_error.clamp(-1, 1)\n",
    "# # # Note: clipped_bellman_delta * -1 will be right gradient\n",
    "# # d_error = clipped_bellman_error * -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2])\n",
      "torch.Size([3, 6])\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "if USE_CUDA:\n",
    "    action = action.cuda()\n",
    "    reward = reward.cuda()\n",
    "print(action)\n",
    "current_q = model_Q.forward(state)\n",
    "current_q_value = current_q.gather(1, action.view(-1,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    next_q_value = model_target_Q.forward(next_state).detach()\n",
    "    target_q_val = reward + ( (gamma**args.N)* (np.max(next_q_value.detach().cpu().numpy())) * (1-done))\n",
    "target_q_val = target_q_val.view(-1,1)\n",
    "print(current_q.shape)\n",
    "print(current_q_value.shape)\n",
    "print(target_q_val.shape)\n",
    "# loss = torch.mean((target_q_val - current_q_value)**2)\n",
    "loss = torch.nn.SmoothL1Loss(target_q_val, current_q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8305, 0.8839, 0.1926])\n",
      "1\n",
      "torch.Size([])\n",
      "tensor([1, 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-7f7a875835aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "a = torch.rand(3)\n",
    "print(a)\n",
    "b = torch.argmax(a)\n",
    "print(b.item())\n",
    "print(b.size())\n",
    "c = torch.from_numpy(np.array([1,2]))\n",
    "print (c)\n",
    "print(int(c.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import namedtuple\n",
    "# Transition = namedtuple('Transition', \n",
    "#                         ['state', 'action', 'reward', 'next_state', 'done'])\n",
    "# batch = zip(*transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2178)\n",
      "tensor(0.0020)\n",
      "tensor(0.0819)\n",
      "tensor(2.9654e-05)\n",
      "tensor([[0.4667, 0.0447],\n",
      "        [0.2862, 0.0054]])\n",
      "tensor([[2.1784e-01, 1.9990e-03],\n",
      "        [8.1929e-02, 2.9654e-05]])\n",
      "tensor([[0.2306, 0.0211],\n",
      "        [0.1352, 0.0128]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand((2,2))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        print(a[i,j]*a[i,j])\n",
    "print(a)\n",
    "print(a**2)\n",
    "print(a@a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep Q run with default params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 1000000\n",
    "batch_size = 32\n",
    "gamma = 0.99\n",
    "    \n",
    "replay_initial = 10000\n",
    "replay_buffer = ReplayBuffer(10000)\n",
    "\n",
    "model = QLearner(env, num_frames, batch_size, gamma, replay_buffer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 30000\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx in range(1, num_frames + 1):\n",
    "\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = model.act(state, epsilon)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "\n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        loss = compute_td_loss(model, batch_size, gamma, replay_buffer)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "    if frame_idx % 10000 == 0 and len(replay_buffer) <= replay_initial:\n",
    "        print('#Frame: %d, preparing replay buffer' % frame_idx)\n",
    "        print(len(replay_buffer))\n",
    "    if frame_idx % 10000 == 0 and len(replay_buffer) > replay_initial:\n",
    "        print('#Frame: %d, Loss: %f' % (frame_idx, np.mean(losses)))\n",
    "        print('Last-10 average reward: %f' % np.mean(all_rewards[-10:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ReplayBuffer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-65819d62e983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreplay_initial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;31m#50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mreplay_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ReplayBuffer' is not defined"
     ]
    }
   ],
   "source": [
    "model_result_path = '../results/DQN/model_default_lr3e_5.pth'\n",
    "\n",
    "replay_initial = 10000 #50000\n",
    "replay_buffer = ReplayBuffer(args.capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new = QLearner(env, args, replay_buffer)\n",
    "model_new.load_state_dict(torch.load(result_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7a82e4f9f5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_deepmind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000000000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_by_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mObservationWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRewardWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-bf7a4444050a>\u001b[0m in \u001b[0;36mobservation\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "env_id = \"PongNoFrameskip-v4\"\n",
    "env = make_atari(env_id)\n",
    "env = wrap_deepmind(env)\n",
    "env = wrap_pytorch(env)\n",
    "state = env.reset()\n",
    "for ii in range(10000000000000):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = model_new.act(state, epsilon)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    state = next_state\n",
    "    if ii % 10 == 0:\n",
    "        env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Environment\n",
    "# env_id = \"PongNoFrameskip-v4\"\n",
    "# env = make_atari(env_id)\n",
    "# env = wrap_deepmind(env)\n",
    "# env = wrap_pytorch(env)\n",
    "# state = env.reset()\n",
    "# for ii in range(10000):\n",
    "#     epsilon = epsilon_by_frame(frame_idx)\n",
    "#     action = model_new.act(state, epsilon)\n",
    "#     next_state, reward, done, _ = env.step(action)\n",
    "#     state = next_state\n",
    "#     if ii%100==0:\n",
    "#         env.render()\n",
    "#         env.close()\n",
    "#         plt.ioff()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "log_path = '../results/DQN/slurm-90336.out'\n",
    "# def parse_traning_logs(log_path):\n",
    "with open(log_path) as logfile :\n",
    "    raw_log_data = logfile.readlines()\n",
    "    \n",
    "    log_data = {}\n",
    "    set_count = 0\n",
    "    set_label = None\n",
    "    frames = []; losses = []; tot_rews = []; avg_all_frames = []; last_ten_avgs = []; best_mean_last_tens = []\n",
    "    times = []; tot_times = []\n",
    "    for log in raw_log_data:\n",
    "        if log.startswith('Frame'):\n",
    "            frame, loss, tot_rew, avg_all_frame, \\\n",
    "            _, last_ten_avg, _, best_mean_last_ten,\\\n",
    "            time, tot_time = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", log)\n",
    "            frames.append(int(frame))\n",
    "            losses.append(float(loss))\n",
    "            tot_rews.append(float(tot_rew))\n",
    "            avg_all_frames.append(float(avg_all_frame))\n",
    "            last_ten_avgs.append(float(last_ten_avg))\n",
    "            best_mean_last_tens.append(float(best_mean_last_ten))\n",
    "            times.append(float(time))\n",
    "            tot_times.append(float(tot_time))\n",
    "        if log.startswith('Namespace'):\n",
    "            aa = re.findall(r\"lr=\\d*e[-+]\\d*\", log)\n",
    "            _,lr = aa[0].split('=')\n",
    "\n",
    "        log_data['Learning Rate'] = lr\n",
    "        log_data['Frames'] = frames\n",
    "        log_data['Loss'] = losses\n",
    "        log_data['Total rewards'] = tot_rews\n",
    "        log_data['Average Rewards over all frames'] = avg_all_frames\n",
    "        log_data['Mean reward (Past 10 episodes)'] = last_ten_avgs\n",
    "        log_data['Best Mean reward (Past 10 episodes)'] = best_mean_last_tens\n",
    "        \n",
    "        \n",
    "print('done')\n",
    "log_data= pd.DataFrame(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Frames</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Total rewards</th>\n",
       "      <th>Average Rewards over all frames</th>\n",
       "      <th>Mean reward (Past 10 episodes)</th>\n",
       "      <th>Best Mean reward (Past 10 episodes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-20.500000</td>\n",
       "      <td>-20.7</td>\n",
       "      <td>-20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-20.096774</td>\n",
       "      <td>-19.2</td>\n",
       "      <td>-19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>40000</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-19.684211</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>-17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.006610</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-19.272727</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-19.020000</td>\n",
       "      <td>-16.7</td>\n",
       "      <td>-16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>70000</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-18.821429</td>\n",
       "      <td>-17.2</td>\n",
       "      <td>-16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>80000</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.540984</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>-16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.388060</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>100000</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-18.236111</td>\n",
       "      <td>-16.6</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>110000</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-18.090909</td>\n",
       "      <td>-16.1</td>\n",
       "      <td>-16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-17.804878</td>\n",
       "      <td>-14.7</td>\n",
       "      <td>-14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>130000</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-17.574713</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>-13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.006484</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-17.239130</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>150000</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-17.092784</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>160000</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.930693</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>170000</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.773585</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>180000</td>\n",
       "      <td>0.006052</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.639640</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>190000</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-16.495652</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>-12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>200000</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-16.283333</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>210000</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-16.256000</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>-12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>220000</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-16.184615</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>230000</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-16.022222</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>-12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>240000</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-15.899281</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>-11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>250000</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-15.812500</td>\n",
       "      <td>-12.6</td>\n",
       "      <td>-11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>260000</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-15.711409</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>-11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>270000</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-15.655844</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>-11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>280000</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-15.550633</td>\n",
       "      <td>-13.1</td>\n",
       "      <td>-11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>290000</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-15.456790</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>-11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>300000</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-15.301205</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>-10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>310000</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-15.192982</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>-10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>670000</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-11.378738</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>680000</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-11.219672</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>690000</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-11.129870</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>700000</td>\n",
       "      <td>0.003953</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>710000</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.917197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>720000</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-10.829653</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>730000</td>\n",
       "      <td>0.003901</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.750779</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>740000</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.645062</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>750000</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-10.495413</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>760000</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-10.369697</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>770000</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-10.212575</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>780000</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.109792</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>790000</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.976471</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>800000</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.839650</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>810000</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-9.694524</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>820000</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-9.585714</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>830000</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-9.490085</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>840000</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-9.384831</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>850000</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-9.208333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>860000</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-9.027473</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>870000</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-8.866485</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>880000</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-8.620968</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>890000</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-8.517333</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>900000</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8.396825</td>\n",
       "      <td>7.4</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>910000</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-8.198953</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>920000</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.010363</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>930000</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.838462</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>940000</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-7.616751</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>950000</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-7.373434</td>\n",
       "      <td>12.4</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3e-05</td>\n",
       "      <td>960000</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-7.181141</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Frames      Loss  Total rewards  \\\n",
       "0          3e-05   20000  0.008733          -20.0   \n",
       "1          3e-05   30000  0.006192          -16.0   \n",
       "2          3e-05   40000  0.006137          -15.0   \n",
       "3          3e-05   50000  0.006610          -14.0   \n",
       "4          3e-05   60000  0.007163          -17.0   \n",
       "5          3e-05   70000  0.007478          -16.0   \n",
       "6          3e-05   80000  0.007512          -17.0   \n",
       "7          3e-05   90000  0.007395          -17.0   \n",
       "8          3e-05  100000  0.007198          -18.0   \n",
       "9          3e-05  110000  0.006975          -16.0   \n",
       "10         3e-05  120000  0.006806          -15.0   \n",
       "11         3e-05  130000  0.006650           -9.0   \n",
       "12         3e-05  140000  0.006484           -9.0   \n",
       "13         3e-05  150000  0.006352          -17.0   \n",
       "14         3e-05  160000  0.006231          -15.0   \n",
       "15         3e-05  170000  0.006138          -15.0   \n",
       "16         3e-05  180000  0.006052          -16.0   \n",
       "17         3e-05  190000  0.005985          -12.0   \n",
       "18         3e-05  200000  0.005901          -13.0   \n",
       "19         3e-05  210000  0.005828          -16.0   \n",
       "20         3e-05  220000  0.005760          -13.0   \n",
       "21         3e-05  230000  0.005686          -12.0   \n",
       "22         3e-05  240000  0.005619           -7.0   \n",
       "23         3e-05  250000  0.005554          -13.0   \n",
       "24         3e-05  260000  0.005498          -15.0   \n",
       "25         3e-05  270000  0.005446          -10.0   \n",
       "26         3e-05  280000  0.005395          -10.0   \n",
       "27         3e-05  290000  0.005341          -13.0   \n",
       "28         3e-05  300000  0.005286          -15.0   \n",
       "29         3e-05  310000  0.005235          -16.0   \n",
       "..           ...     ...       ...            ...   \n",
       "65         3e-05  670000  0.004009           -1.0   \n",
       "66         3e-05  680000  0.003990            6.0   \n",
       "67         3e-05  690000  0.003972            3.0   \n",
       "68         3e-05  700000  0.003953            3.0   \n",
       "69         3e-05  710000  0.003935            2.0   \n",
       "70         3e-05  720000  0.003917           -4.0   \n",
       "71         3e-05  730000  0.003901            3.0   \n",
       "72         3e-05  740000  0.003886            4.0   \n",
       "73         3e-05  750000  0.003870            5.0   \n",
       "74         3e-05  760000  0.003856            3.0   \n",
       "75         3e-05  770000  0.003842            7.0   \n",
       "76         3e-05  780000  0.003828            4.0   \n",
       "77         3e-05  790000  0.003813            4.0   \n",
       "78         3e-05  800000  0.003798            3.0   \n",
       "79         3e-05  810000  0.003785            3.0   \n",
       "80         3e-05  820000  0.003772           -7.0   \n",
       "81         3e-05  830000  0.003759            4.0   \n",
       "82         3e-05  840000  0.003746           -1.0   \n",
       "83         3e-05  850000  0.003735           10.0   \n",
       "84         3e-05  860000  0.003724           13.0   \n",
       "85         3e-05  870000  0.003711           13.0   \n",
       "86         3e-05  880000  0.003700           10.0   \n",
       "87         3e-05  890000  0.003691            3.0   \n",
       "88         3e-05  900000  0.003684            2.0   \n",
       "89         3e-05  910000  0.003676           17.0   \n",
       "90         3e-05  920000  0.003666            7.0   \n",
       "91         3e-05  930000  0.003654            9.0   \n",
       "92         3e-05  940000  0.003642           14.0   \n",
       "93         3e-05  950000  0.003633           13.0   \n",
       "94         3e-05  960000  0.003624            9.0   \n",
       "\n",
       "    Average Rewards over all frames  Mean reward (Past 10 episodes)  \\\n",
       "0                        -20.500000                           -20.7   \n",
       "1                        -20.096774                           -19.2   \n",
       "2                        -19.684211                           -17.9   \n",
       "3                        -19.272727                           -17.0   \n",
       "4                        -19.020000                           -16.7   \n",
       "5                        -18.821429                           -17.2   \n",
       "6                        -18.540984                           -16.5   \n",
       "7                        -18.388060                           -16.0   \n",
       "8                        -18.236111                           -16.6   \n",
       "9                        -18.090909                           -16.1   \n",
       "10                       -17.804878                           -14.7   \n",
       "11                       -17.574713                           -13.6   \n",
       "12                       -17.239130                           -12.6   \n",
       "13                       -17.092784                           -12.9   \n",
       "14                       -16.930693                           -13.3   \n",
       "15                       -16.773585                           -13.7   \n",
       "16                       -16.639640                           -13.7   \n",
       "17                       -16.495652                           -13.4   \n",
       "18                       -16.283333                           -12.3   \n",
       "19                       -16.256000                           -13.5   \n",
       "20                       -16.184615                           -15.0   \n",
       "21                       -16.022222                           -13.1   \n",
       "22                       -15.899281                           -11.9   \n",
       "23                       -15.812500                           -12.6   \n",
       "24                       -15.711409                           -13.1   \n",
       "25                       -15.655844                           -13.4   \n",
       "26                       -15.550633                           -13.1   \n",
       "27                       -15.456790                           -11.8   \n",
       "28                       -15.301205                           -10.2   \n",
       "29                       -15.192982                           -10.7   \n",
       "..                              ...                             ...   \n",
       "65                       -11.378738                            -1.3   \n",
       "66                       -11.219672                            -0.6   \n",
       "67                       -11.129870                            -1.1   \n",
       "68                       -11.000000                             0.4   \n",
       "69                       -10.917197                             0.0   \n",
       "70                       -10.829653                            -0.2   \n",
       "71                       -10.750779                            -3.0   \n",
       "72                       -10.645062                            -2.1   \n",
       "73                       -10.495413                             0.1   \n",
       "74                       -10.369697                             3.2   \n",
       "75                       -10.212575                             3.8   \n",
       "76                       -10.109792                             2.5   \n",
       "77                        -9.976471                             3.0   \n",
       "78                        -9.839650                             4.3   \n",
       "79                        -9.694524                             4.3   \n",
       "80                        -9.585714                             3.7   \n",
       "81                        -9.490085                             2.5   \n",
       "82                        -9.384831                             2.6   \n",
       "83                        -9.208333                             4.0   \n",
       "84                        -9.027473                             6.0   \n",
       "85                        -8.866485                             8.5   \n",
       "86                        -8.620968                             9.4   \n",
       "87                        -8.517333                             7.8   \n",
       "88                        -8.396825                             7.4   \n",
       "89                        -8.198953                             7.5   \n",
       "90                        -8.010363                             9.5   \n",
       "91                        -7.838462                             9.9   \n",
       "92                        -7.616751                            10.6   \n",
       "93                        -7.373434                            12.4   \n",
       "94                        -7.181141                            12.1   \n",
       "\n",
       "    Best Mean reward (Past 10 episodes)  \n",
       "0                                 -20.7  \n",
       "1                                 -19.2  \n",
       "2                                 -17.9  \n",
       "3                                 -17.0  \n",
       "4                                 -16.7  \n",
       "5                                 -16.7  \n",
       "6                                 -16.5  \n",
       "7                                 -16.0  \n",
       "8                                 -16.0  \n",
       "9                                 -16.0  \n",
       "10                                -14.7  \n",
       "11                                -13.6  \n",
       "12                                -12.6  \n",
       "13                                -12.6  \n",
       "14                                -12.6  \n",
       "15                                -12.6  \n",
       "16                                -12.6  \n",
       "17                                -12.6  \n",
       "18                                -12.3  \n",
       "19                                -12.3  \n",
       "20                                -12.3  \n",
       "21                                -12.3  \n",
       "22                                -11.9  \n",
       "23                                -11.9  \n",
       "24                                -11.9  \n",
       "25                                -11.9  \n",
       "26                                -11.9  \n",
       "27                                -11.8  \n",
       "28                                -10.2  \n",
       "29                                -10.2  \n",
       "..                                  ...  \n",
       "65                                 -1.3  \n",
       "66                                 -0.6  \n",
       "67                                 -0.6  \n",
       "68                                  0.4  \n",
       "69                                  0.4  \n",
       "70                                  0.4  \n",
       "71                                  0.4  \n",
       "72                                  0.4  \n",
       "73                                  0.4  \n",
       "74                                  3.2  \n",
       "75                                  3.8  \n",
       "76                                  3.8  \n",
       "77                                  3.8  \n",
       "78                                  4.3  \n",
       "79                                  4.3  \n",
       "80                                  4.3  \n",
       "81                                  4.3  \n",
       "82                                  4.3  \n",
       "83                                  4.3  \n",
       "84                                  6.0  \n",
       "85                                  8.5  \n",
       "86                                  9.4  \n",
       "87                                  9.4  \n",
       "88                                  9.4  \n",
       "89                                  9.4  \n",
       "90                                  9.5  \n",
       "91                                  9.9  \n",
       "92                                 10.6  \n",
       "93                                 12.4  \n",
       "94                                 12.4  \n",
       "\n",
       "[95 rows x 7 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure \n",
    "from bokeh.models import Legend\n",
    "from bokeh.layouts import column\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "plot_priority_order = [\n",
    "        'Mean reward (Past 10 episodes)',\n",
    "        'Best Mean reward (Past 10 episodes)',\n",
    "        'Loss',\n",
    "#         'Total rewards',\n",
    "#         'Average Rewards over all frames',\n",
    "#         'Learning Rate',\n",
    "#         'Frames'    \n",
    "    ]\n",
    "plots = []\n",
    "for key in plot_priority_order:\n",
    "    plots.append(figure(plot_width=900, plot_height=300, y_axis_label=key, x_axis_label='Frames'))\n",
    "    plots[-1].line(log_data[key].index, log_data[key], line_width=2)\n",
    "main_row = column(*plots)\n",
    "show(main_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, axis = plt.subplots(1,2)\n",
    "\n",
    "# plot_priority_order = [\n",
    "#         'Mean reward (Past 10 episodes)',\n",
    "# #         'Best Mean reward (Past 10 episodes)',\n",
    "# #         'Loss',\n",
    "# #         'Total rewards',\n",
    "# #         'Average Rewards over all frames',\n",
    "# #         'Learning Rate',\n",
    "# #         'Frames'    \n",
    "#     ]\n",
    "\n",
    "plt.figure(1,figsize=(10,20))\n",
    "plt.subplot(211)\n",
    "plt.plot(log_data['Frames'].values,log_data['Mean reward (Past 10 episodes)'].values)\n",
    "plt.subplot(212)\n",
    "plt.plot(log_data['Frames'].values,log_data['Loss'].values)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
